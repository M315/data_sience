{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1f2e54",
   "metadata": {},
   "source": [
    "# 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf6356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d8e73",
   "metadata": {},
   "source": [
    "## Manual regresio using gradient descent\n",
    "\n",
    "Will use pytorch backpropagation to compute the gradients and improve our model using gradient descent to minimize the mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d20da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "data = pd.read_csv('data/weight-height.csv').replace(['Male', 'Female'], [100., 0.]).div(100)\n",
    "\n",
    "grad_inputs = torch.from_numpy(data[[\"Gender\", \"Height\"]].to_numpy().astype('float32'))\n",
    "grad_targets = torch.from_numpy(np.array([a.item() for a in data[[\"Weight\"]].to_numpy()], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a373862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5345, -0.3446], requires_grad=True)\n",
      "tensor([-2.5787], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "grad_w = torch.randn(2, requires_grad=True)\n",
    "grad_b = torch.randn(1, requires_grad=True)\n",
    "print(grad_w)\n",
    "print(grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a00767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_model(x):\n",
    "    return x @ grad_w + grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ad87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def grad_mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061cbc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0251, grad_fn=<DivBackward0>)\n",
      "tensor([1.9570, 1.8769, 1.9611,  ..., 1.3490, 1.4306, 1.3186],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([2.4189, 1.6231, 2.1274,  ..., 1.2848, 1.6385, 1.1365])\n"
     ]
    }
   ],
   "source": [
    "# Train for n epochs\n",
    "for i in range(100000):\n",
    "    preds = grad_model(grad_inputs)\n",
    "    loss = grad_mse(preds, grad_targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        grad_w -= grad_w.grad * 1e-4\n",
    "        grad_b -= grad_b.grad * 1e-4\n",
    "        grad_w.grad.zero_()\n",
    "        grad_b.grad.zero_()\n",
    "        \n",
    "grad_preds = grad_model(grad_inputs)\n",
    "grad_loss = grad_mse(grad_preds, grad_targets)\n",
    "print(grad_loss)\n",
    "print(grad_preds)\n",
    "print(grad_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c51d9",
   "metadata": {},
   "source": [
    "## \"Neural Network\" Aproach\n",
    "\n",
    "A forward neural network with no hiden lyers is equivalent to a linear regresion. So we will use pytorch nn utility to make the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35fc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c198794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "data = pd.read_csv('data/weight-height.csv').replace(['Male', 'Female'], [100., 0.]).div(100)\n",
    "\n",
    "inputs = torch.from_numpy(data[[\"Gender\", \"Height\"]].to_numpy().astype('float32'))\n",
    "targets = torch.from_numpy(np.array([a for a in data[[\"Weight\"]].to_numpy()], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526810db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0421,  0.6506]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4891], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "\n",
    "# Define data loader\n",
    "batch_size = len(inputs) // 10\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "model = torch.nn.Linear(2, 1)\n",
    "print(list(model.parameters()))\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "\n",
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b1b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % (num_epochs // 20) == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "219f9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/5000], Loss: 0.5391\n",
      "Epoch [500/5000], Loss: 0.1160\n",
      "Epoch [750/5000], Loss: 0.0438\n",
      "Epoch [1000/5000], Loss: 0.0304\n",
      "Epoch [1250/5000], Loss: 0.0297\n",
      "Epoch [1500/5000], Loss: 0.0278\n",
      "Epoch [1750/5000], Loss: 0.0252\n",
      "Epoch [2000/5000], Loss: 0.0245\n",
      "Epoch [2250/5000], Loss: 0.0271\n",
      "Epoch [2500/5000], Loss: 0.0272\n",
      "Epoch [2750/5000], Loss: 0.0246\n",
      "Epoch [3000/5000], Loss: 0.0273\n",
      "Epoch [3250/5000], Loss: 0.0265\n",
      "Epoch [3500/5000], Loss: 0.0268\n",
      "Epoch [3750/5000], Loss: 0.0272\n",
      "Epoch [4000/5000], Loss: 0.0276\n",
      "Epoch [4250/5000], Loss: 0.0268\n",
      "Epoch [4500/5000], Loss: 0.0278\n",
      "Epoch [4750/5000], Loss: 0.0275\n",
      "Epoch [5000/5000], Loss: 0.0260\n"
     ]
    }
   ],
   "source": [
    "fit(5000, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e0ed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.4494, 1.3426]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4992], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132e12",
   "metadata": {},
   "source": [
    "# statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd34c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66719692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "data = pd.read_csv('data/weight-height.csv').replace(['Male', 'Female'], [100., 0.]).div(100)\n",
    "\n",
    "X = data[[\"Gender\", \"Height\"]].to_numpy().astype('float32')\n",
    "Y = data[[\"Weight\"]].to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88cd32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.903\n",
      "Model:                            OLS   Adj. R-squared:                  0.903\n",
      "Method:                 Least Squares   F-statistic:                 4.640e+04\n",
      "Date:                Thu, 31 Mar 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:24:51   Log-Likelihood:                 8823.9\n",
      "No. Observations:               10000   AIC:                        -1.764e+04\n",
      "Df Residuals:                    9997   BIC:                        -1.762e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.4492      0.023   -106.552      0.000      -2.494      -2.404\n",
      "x1             0.1938      0.003     69.931      0.000       0.188       0.199\n",
      "x2             5.9769      0.036    165.973      0.000       5.906       6.048\n",
      "==============================================================================\n",
      "Omnibus:                        0.464   Durbin-Watson:                   2.016\n",
      "Prob(Omnibus):                  0.793   Jarque-Bera (JB):                0.447\n",
      "Skew:                           0.016   Prob(JB):                        0.800\n",
      "Kurtosis:                       3.011   Cond. No.                         56.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
